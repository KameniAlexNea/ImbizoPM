{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ed2fd",
   "metadata": {},
   "source": [
    "# ImbizoPM Agents Test\n",
    "\n",
    "This notebook demonstrates how to use the ImbizoPM agents to create and execute a project planning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbizopm_agents.graph import create_project_planning_graph, run_project_planning_graph\n",
    "from IPython.display import display, Image\n",
    "from langgraph.graph.graph import CompiledGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daba6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"ollama:cogito:32b\")\n",
    "\n",
    "# llm.invoke(\"Say 'hello'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the project planning graph with checkpointing enabled\n",
    "graph: CompiledGraph = create_project_planning_graph(llm, use_checkpointing=True, use_structured_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1286b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54ffbe",
   "metadata": {},
   "source": [
    "## Running the Project Planning Process\n",
    "\n",
    "We run the project planning graph with a sample input. The system will process the input through all the agents in the workflow and may request human assistance when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d876880",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT1 = \"\"\"\n",
    "Predict clinician responses to real-world clinical vignettes from rural Kenya, replicating expert nurse decision-making under low-resource healthcare constraints.\n",
    "\"\"\"\n",
    "\n",
    "PROJECT2 = \"\"\"\n",
    "AgentFlow is a Python library that automates the orchestration of multi-step agent workflows by integrating intelligent planning, routing, and execution of specialized operations.\n",
    "\"\"\"\n",
    "\n",
    "PROJECT = \"\"\"\n",
    "# Kenya-Clinical-Reasoning-Challenge\n",
    "\n",
    "Zindi Challange : Predict clinician responses to real-world clinical vignettes from rural Kenya, replicating expert nurse decision-making under low-resource healthcare constraints.\n",
    "\n",
    "## Can your model match real clinicians in rural Kenyan healthcare?\n",
    "\n",
    "In many parts of the world, frontline healthcare workers make life-or-death decisions under pressure, with limited resources and specialist support. This challenge takes you to the heart of Kenyan healthcare, where nurses working across diverse counties and health facility levels face real-world clinical cases every day.\n",
    "\n",
    "In this challenge, you'll be given 400 authentic clinical prompts—each one a carefully crafted vignette combining a nurse’s background and a complex medical situation. Your task is to predict the clinician’s response to each scenario, replicating the reasoning of trained professionals as closely as possible.\n",
    "\n",
    "The vignettes span a wide range of medical domains, from maternal and child health to critical care, and were originally evaluated by expert clinicians and leading AI models (including GPT-4.0, LLAMA, and GEMINI). Each prompt includes details like the patient's presentation, nurse experience level, and facility type, simulating the nuance and challenge of real clinical environments in Kenya.\n",
    "\n",
    "This dataset is small—only 400 training and 100 test samples—but that’s because collecting high-quality, expert-labelled medical data is hard. These are real-world cases, and every entry reflects the constraints and pressures faced by healthcare workers in underserved regions. In resource-limited settings, clinical decisions must be fast, accurate, and sensitive to both patient condition and system limitations. Your solution should aim to reflect that balance.\n",
    "\n",
    "## About\n",
    "\n",
    "The dataset contains real-world clinical vignettes drawn from frontline healthcare settings across Kenya. Each sample presents a prompt representing a clinical case scenario, along with the response from a human clinician. Your goal is to predict the clinician's response based on the prompt.\n",
    "\n",
    "These vignettes simulate the types of decisions nurses in Kenya must make every day, particularly in low-resource environments where access to specialists or diagnostic equipment may be limited.\n",
    "\n",
    "Each prompt was originally answered by expert clinicians as well as multiple large language models (LLMs) as part of a research initiative on AI in healthcare. For this challenge, we focus only on replicating the human clinician response.\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "* These are real clinical scenarios, and the dataset is small because expert-labelled data is difficult and time-consuming to collect.\n",
    "* Prompts are diverse across medical specialties, geographic regions, and healthcare facility levels, requiring broad clinical reasoning and adaptability.\n",
    "* Responses may include abbreviations, structured reasoning (e.g. \"Summary:\", \"Diagnosis:\", \"Plan:\"), or free text.\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The evaluation metric for this challenge is the [ROUGE Score](https://zindi.africa/blog/zindi-error-metric-series-how-to-use-rouge-f-measure-for-machine-translation).\n",
    "\n",
    "All clinician responses have been turned to lower case, punctuation removed and all paragraphs replaced with a space.\n",
    "\n",
    "For every row in the dataset, submission files should contain 2 columns: ID and Translation.\n",
    "\n",
    "Your submission file should look like this:\n",
    "\n",
    "```\n",
    "Master_Index     Clinician\n",
    "```\n",
    "\n",
    "```\n",
    "ID_AAAitMaH      summary a 30 yr old...\n",
    "```\n",
    "\n",
    "If you are in the top 10 on the leaderboard you will be requested to prepare a [video](https://www.youtube.com/watch?v=oOaoWTd---E) to share with the host along with your code.\n",
    "\n",
    "In the video you submit, you need to explain your approach to the problem as clearly as possible, including any relevant insights into the problem you discovered along the way (e.g. a clever way to engineer the raw features).\n",
    "\n",
    "Final prizes will be judged and awarded by the host, based on the following criteria.\n",
    "\n",
    "* The clarity of your pitch (how easy is it to understand the solution) - 25%\n",
    "* The insights you obtained from tackling the problem - 15%\n",
    "* How implementable is your code in a real application? Have you taken into account that the solution will be deployed on an edge device? - 25%\n",
    "* Novel ideas taking into account complexities and real world applications - 25%\n",
    "* Code that is clean, easy to read and work with - 10%\n",
    "\n",
    "## Resource Restrictions\n",
    "\n",
    "Your solution must be\n",
    "\n",
    "* Quantized to reduce memory usage and improve inference speed\n",
    "* Inference must be less than 100ms per vignette\n",
    "* Inference RAM usage of less than 2 GB\n",
    "* The maximum number of model parameters is 1 billion parameters\n",
    "* Training should take no longer than 24 hours on a GPU similar to an NVIDIA T4 while inference should be on an NVIDIA Jetson Nano or equivalent.\n",
    "\n",
    "Prizes\n",
    "\n",
    "1st place: $5 000 USD\n",
    "\n",
    "2nd place: $3 000 USD\n",
    "\n",
    "3rd place: $2 000 USD\n",
    "\n",
    "There are 5 000 Zindi points available. You can read more about [Zindi points here](https://zindi.africa/discussions/13959?utm_source=zindi&utm_medium=blog&utm_campaign=challenge_resources&utm_id=CR).\n",
    "\n",
    "The results of this challenge will be written in a publication and challenge winners acknowledged as authors.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bba906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the project planning process\n",
    "results = []\n",
    "for result in run_project_planning_graph(\n",
    "    graph,\n",
    "    user_input=PROJECT,\n",
    "    thread_id=\"demo-run-1\",  # Adding a unique thread ID for this run\n",
    "    recursion_limit = 30\n",
    "):\n",
    "    results.append(result)\n",
    "\n",
    "# Display the number of steps processed\n",
    "print(f\"Process completed with {len(results)} steps\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
